{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#importing some useful packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "\n",
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip \n",
    "from IPython.display import HTML\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#change the BGR image to grayscale \n",
    "def grayscale(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#perform canny edge detection\n",
    "def canny(img, low_threshold, high_threshold):\n",
    "    \"\"\"Applies the Canny transform\"\"\"\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "#perform Gaussian Blur\n",
    "def gaussian_blur(img, kernel_size):\n",
    "    \"\"\"Applies a Gaussian Noise kernel\"\"\"\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ROI detection based on the polygon created using vertices\n",
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    \n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    \"\"\"\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is where the actual changes lies from the template\n",
    "\n",
    "#Things considered:\n",
    "# Lets divide the image into two halfs, left half and right half\n",
    "#it was found during experiments that sometimes in left half, some line segments show up that have an opposite sloe compared to all the other segments in the same half.\n",
    "#Hence, we remove the line segments that have opposite slope than what is expected from the left half\n",
    "#In short, we remove the line segments that have different slope from than the expected slope (positive or negative depending on left or right half)\n",
    "#The expected thing is that the line segments in the left half should have negative slope while the line segments in the right half should have postive slop\n",
    "\n",
    "def draw_lines_modified (line_img, lines,color=[255, 0, 0], thickness=4):\n",
    "    count = 0 \n",
    "    count1 = 0\n",
    "    left_x1 = lefty1 = left_x2 = left_y2 = 0\n",
    "    right_x1 = right_x2 = right_y1 = right_y2 = 0\n",
    "    \n",
    "    \n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "                \n",
    "                slope = (y2-y1)/(x2-x1)\n",
    "                #print(slope)\n",
    "                if (slope < 0):# we check if the slope is negative, if negative, it should be in left half\n",
    "                    if (x2 > 500):#checking if the line segments lie in right half, if yes, reject them \n",
    "                        continue\n",
    "                    if (x1 > 500):#checking if the line segments lie in right half, if yes, dont consider them\n",
    "                        continue\n",
    "                    #print(x1, y1, x2, y2)\n",
    "                    #cv2.line(line_img, (x1, y1), (x2, y2), color, thickness)\n",
    "                    \n",
    "                    if (count == 0):\n",
    "                        left_x1 = x1\n",
    "                        left_y1 = y1\n",
    "                        left_x2 = x2\n",
    "                        left_y2 = y2\n",
    "                        count = count + 1\n",
    "                        \n",
    "                    else:\n",
    "                        if (x1 < left_x1):#taking the end values\n",
    "                            left_x1 = x1\n",
    "                            left_y1 = y1\n",
    "                        if (x2 > left_x2):\n",
    "                            left_x2 = x2\n",
    "                            left_y2 = y2\n",
    "                    \n",
    "                elif (slope > 0):# we check if the slope is postive, if yes, it should be in right half\n",
    "                    if (x2 < 500):\n",
    "                        continue\n",
    "                    if (x1 < 500):# rejecting the ones that are not in the right half\n",
    "                        continue\n",
    "                    #cv2.line(line_img, (x1, y1), (x2, y2), color, thickness)\n",
    "                    #print(x1, y1, x2, y2)\n",
    "                    #cv2.line(line_img, (x1, y1), (x2, y2), color, thickness)\n",
    "                    \n",
    "                    if (count1 == 0):\n",
    "                        right_x1 = x1\n",
    "                        right_y1 = y1\n",
    "                        right_x2 = x2\n",
    "                        right_y2 = y2\n",
    "                        count1 = count1 + 1\n",
    "                        \n",
    "                    else:#finding the lend tips of all line segments\n",
    "                        if (x1 < right_x1):\n",
    "                            right_x1 = x1\n",
    "                            right_y1 = y1\n",
    "                        if (x2 > right_x2):\n",
    "                            right_x2 = x2\n",
    "                            right_y2 = y2\n",
    "                    \n",
    "\n",
    "                else:\n",
    "                    print(\"first pass done...\")\n",
    "\n",
    "    slope_left = (left_y2-left_y1)/(left_x2-left_x1)# estimating line slope from the found line tips in the left half\n",
    "    c_left = left_y2-(slope_left*left_x2)\n",
    "    new_left_y3 = 539;#y=mx+c\n",
    "    new_left_x3 = (int)(new_left_y3-c_left)/slope_left#from the line equation, estimate the end points\n",
    "    new_left_x3 = int(new_left_x3)\n",
    "   \n",
    "    \n",
    "    new_left_y4 = 330;#y=mx+c\n",
    "    new_left_x4 = (int)(new_left_y4-c_left)/slope_left\n",
    "    new_left_x4 = int(new_left_x4)  #from the line equation, estimate the end points\n",
    "\n",
    "    cv2.line(line_img, (new_left_x3, new_left_y3), (new_left_x4, new_left_y4), color, thickness)#draw estimated line\n",
    "    \n",
    "    slope_right = (right_y2-right_y1)/(right_x2-right_x1)# estimating line slope from the found line tips in the right half\n",
    "    c_right = right_y2-(slope_right*right_x2)\n",
    "    new_right_y3 = 539;#y=mx+c\n",
    "    new_right_x3 = (int)(new_right_y3-c_right)/slope_right #from the line equation, estimate the end points\n",
    "    new_right_x3 = int(new_right_x3)\n",
    "\n",
    "\n",
    "   \n",
    "    new_right_y4 = 330;#y=mx+c\n",
    "    new_right_x4 = (int)(new_right_y4-c_right)/slope_right\n",
    "    new_right_x4 = int(new_right_x4) #from the line equation, estimate the end points\n",
    "    #print (new_right_x3, new_right_y3, right_x2, right_y2)\n",
    "\n",
    "\n",
    "    cv2.line(line_img, (new_right_x3, new_right_y3), (new_right_x4, new_right_y4), color, thickness)#draw estimated lines\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hough_lines_mod(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    \"\"\"\n",
    "    `img` should be the output of a Canny transform.\n",
    "        \n",
    "    Returns an image with hough lines drawn.\n",
    "    \"\"\"\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "    draw_lines_modified(line_img, lines)\n",
    "    return line_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weighted_img(img, initial_img, α=0.8, β=1., λ=0.):\n",
    "    \"\"\"\n",
    "    `img` is the output of the hough_lines(), An image with lines drawn on it.\n",
    "    Should be a blank image (all black) with lines drawn on it.\n",
    "    \n",
    "    `initial_img` should be the image before any processing.\n",
    "    \n",
    "    The result image is computed as follows:\n",
    "    \n",
    "    initial_img * α + img * β + λ\n",
    "    NOTE: initial_img and img must be the same shape!\n",
    "    \"\"\"\n",
    "    return cv2.addWeighted(initial_img, α, img, β, λ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    # NOTE: The output you return should be a color image (3 channel) for processing video below\n",
    "    # TODO: put your pipeline here,\n",
    "    # you should return the final output (image where lines are drawn on lanes)\n",
    "    \n",
    "    gray_image = grayscale(image)\n",
    "\n",
    "    blur_image = gaussian_blur (gray_image, 7)\n",
    "\n",
    "    canny_image = canny(blur_image, 70, 140)\n",
    "\n",
    "    points = np.array([[60, 539], [400, 320], [600, 320], [940, 539]])\n",
    "\n",
    "    masked_image = region_of_interest(canny_image,np.int32([points]) )\n",
    "    \n",
    "    hough_image = hough_lines_mod(masked_image, 2, 1, 15, 20, 80)\n",
    "    \n",
    "    lanes_on_image = weighted_img(hough_image, image, 0.6, 5, 0)\n",
    "\n",
    "\n",
    "\n",
    "    return lanes_on_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video test_videos_output/solidWhiteRight.mp4\n",
      "[MoviePy] Writing video test_videos_output/solidWhiteRight.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 221/222 [00:05<00:00, 40.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_videos_output/solidWhiteRight.mp4 \n",
      "\n",
      "CPU times: user 5.06 s, sys: 200 ms, total: 5.26 s\n",
      "Wall time: 6.13 s\n"
     ]
    }
   ],
   "source": [
    "white_output = 'test_videos_output/solidWhiteRight.mp4'\n",
    "#white_output = 'test_videos_output/solidYellowLeft.mp4'\n",
    "\n",
    "\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "##clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(0,5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\")\n",
    "#clip1 = VideoFileClip(\"test_videos/solidYellowLeft.mp4\")\n",
    "\n",
    "\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"test_videos_output/solidWhiteRight.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
